{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecc617b",
   "metadata": {},
   "source": [
    "# Analysis Preparation\n",
    "To begin cleaning the data and prepare for analysis, I will begin by loading the data and identifying the features I seek to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fdb936cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_csv('data/CTDC_global_synthetic_data_v2025.csv')\n",
    "y_variables = ['isForcedLabour', 'isSexualExploit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34928921",
   "metadata": {},
   "source": [
    "My initial filter will restrict the data to entries where the country of exploitation is in North America. Also, I will remove 'type..' features from the dataset. \n",
    "These features contain more detailed information on the types of labor and sexual exploitation experienced and are therefore extremely confounding in terms of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dfb33086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in USA before data cleaning: 117575\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    df\n",
    "    .filter(pl.col('CountryOfExploitation').is_in(['USA', 'MEX', 'CAN']))\n",
    "    .select(pl.exclude([c for c in df.columns if 'type' in c]))\n",
    "    .drop('yearOfRegistration')\n",
    ")\n",
    "print(f\"Number of rows in USA before data cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2f9d3",
   "metadata": {},
   "source": [
    "Next, I will remove any rows where there are no 1s for any of the three types of exploitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ccfa3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exploitation data: 91043\n",
      "Number of rows without exploitation data: 26532\n",
      "Original number of rows: 117575\n"
     ]
    }
   ],
   "source": [
    "has_exploit = (\n",
    "    df['isForcedLabour'].is_not_null() | \n",
    "    df['isSexualExploit'].is_not_null() | \n",
    "    df['isOtherExploit'].is_not_null()\n",
    ")\n",
    "\n",
    "num_with = len(df.filter(has_exploit))\n",
    "num_without = len(df.filter(~has_exploit))\n",
    "original_rows = num_with + num_without\n",
    "print(f\"Number of rows with exploitation data: {num_with}\")\n",
    "print(f\"Number of rows without exploitation data: {num_without}\")\n",
    "print(f\"Original number of rows: {original_rows}\")\n",
    "\n",
    "# Filter to only those rows\n",
    "df = df.filter(has_exploit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f991ac",
   "metadata": {},
   "source": [
    "Now, according to codebook guidelines, I will encode binary features by converting all nulls to 0s. Please see initial pages in guidebook for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "045b9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meansDebtBondageEarnings unique values: [0, 1]\n",
      "meansThreats unique values: [0, 1]\n",
      "meansAbusePsyPhySex unique values: [0, 1]\n",
      "meansFalsePromises unique values: [0, 1]\n",
      "meansDrugsAlcohol unique values: [0, 1]\n",
      "meansDenyBasicNeeds unique values: [0, 1]\n",
      "meansExcessiveWorkHours unique values: [0, 1]\n",
      "meansWithholdDocs unique values: [0, 1]\n",
      "recruiterRelationIntimatePartner unique values: [0, 1]\n",
      "recruiterRelationFriend unique values: [0, 1]\n",
      "recruiterRelationFamily unique values: [0, 1]\n",
      "recruiterRelationOther unique values: [0, 1]\n",
      "isForcedLabour unique values: [0, 1]\n",
      "isSexualExploit unique values: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "feature_groups = {\n",
    "    \"means_of_control\": [\n",
    "        \"meansDebtBondageEarnings\",\n",
    "        \"meansThreats\", \n",
    "        \"meansAbusePsyPhySex\",\n",
    "        \"meansFalsePromises\",\n",
    "        \"meansDrugsAlcohol\",\n",
    "        \"meansDenyBasicNeeds\",\n",
    "        \"meansExcessiveWorkHours\",\n",
    "        \"meansWithholdDocs\"\n",
    "    ],\n",
    "    \"recruiter_relation\": [\n",
    "        \"recruiterRelationIntimatePartner\",\n",
    "        \"recruiterRelationFriend\",\n",
    "        \"recruiterRelationFamily\",\n",
    "        \"recruiterRelationOther\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# encode binary features including target variables\n",
    "binary_cols = [col for cols in feature_groups.values() for col in cols]\n",
    "binary_cols = binary_cols + y_variables\n",
    "df = df.with_columns([\n",
    "    pl.col(col).fill_null(0).cast(pl.Int64)\n",
    "    for col in binary_cols\n",
    "])\n",
    "\n",
    "# verify targets are now binary and do not contain nulls\n",
    "for var in binary_cols:\n",
    "    unique_values = df[var].unique()\n",
    "    print(f\"{var} unique values: {unique_values.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af76ed",
   "metadata": {},
   "source": [
    "Now, I will convert the gender column to dummy variables (one hot encoding). Male will be used as the reference category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f5be7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ageBroad\n",
      "citizenship\n",
      "CountryOfExploitation\n",
      "traffickMonths\n",
      "meansDebtBondageEarnings\n",
      "meansThreats\n",
      "meansAbusePsyPhySex\n",
      "meansFalsePromises\n",
      "meansDrugsAlcohol\n",
      "meansDenyBasicNeeds\n",
      "meansExcessiveWorkHours\n",
      "meansWithholdDocs\n",
      "isForcedLabour\n",
      "isSexualExploit\n",
      "isOtherExploit\n",
      "recruiterRelationIntimatePartner\n",
      "recruiterRelationFriend\n",
      "recruiterRelationFamily\n",
      "recruiterRelationOther\n",
      "gender_Trans/Transgender/NonConforming\n",
      "gender_Woman\n"
     ]
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "    pl.col(\"gender\").fill_null(\"Unknown\"),\n",
    ")\n",
    "gender_dummies = df.select(pl.col(\"gender\")).to_dummies()\n",
    "df = pl.concat([df, gender_dummies], how=\"horizontal\")\n",
    "df = df.drop(\n",
    "    [\"gender\", \"gender_Man\", \"gender_Unknown\"] \n",
    "    )\n",
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1afd49",
   "metadata": {},
   "source": [
    "Next, I will assign numerical encodings to the age bands, beginning at 1 for the youngest grouping and increasing to 9 for the eldest. Unknown ages will receive 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "040bfc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0--8', '27--29', '09--17', '39--47', '18--20', '24--26', '30--38', None, '21--23', '48+']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# identify range of values\n",
    "print(df['ageBroad'].unique().to_list())\n",
    "age_mapping = {\n",
    "    \"0--8\": 1,\n",
    "    \"09--17\": 2,\n",
    "    \"18--20\": 3,\n",
    "    \"21--23\": 4,\n",
    "    \"24--26\": 5,\n",
    "    \"27--29\": 6,\n",
    "    \"30--38\": 7,\n",
    "    \"39--47\": 8,\n",
    "    \"48+\": 9,\n",
    "    \"None\": 0  # Unknown age\n",
    "}\n",
    "df = df.with_columns(\n",
    "    pl.col('ageBroad')\n",
    "    .fill_null(\"None\")\n",
    "    .replace(age_mapping).cast(pl.Int64)\n",
    "    .alias('ageBroad')\n",
    ")\n",
    "# ensure range of values is now integer mapping\n",
    "print(df['ageBroad'].unique().to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3711464",
   "metadata": {},
   "source": [
    "I will follow a similar process for mapping the duration of the trafficking experience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "875a5468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, '25+ (2+ yrs)', '0--12 (0-1 yr)', '13--24 (1-2 yrs)']\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(df['traffickMonths'].unique().to_list())\n",
    "duration_mapping = {\n",
    "    \"0--12 (0-1 yr)\": 1,\n",
    "    \"13--24 (1-2 yrs)\": 2,\n",
    "    \"25+ (2+ yrs)\": 3,\n",
    "    \"None\": 0  # Unknown duration\n",
    "}\n",
    "df = df.with_columns(\n",
    "    pl.col(\"traffickMonths\")\n",
    "    .fill_null(\"None\")\n",
    "    .replace(duration_mapping).cast(pl.Int64)\n",
    "    .alias(\"traffickMonths\")\n",
    ")\n",
    "print(df['traffickMonths'].unique().to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cad64b",
   "metadata": {},
   "source": [
    "Now I will create a derived binary feature indicating whether the victim's citizenship is the same as the country of exploitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "adf7e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "citizenship_in_country = df['citizenship'] == df['CountryOfExploitation']\n",
    "df = df.with_columns(\n",
    "    pl.when(citizenship_in_country)\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias('isCitizenOfCountry')\n",
    ")\n",
    "df = df.drop('citizenship', 'CountryOfExploitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdcf2b",
   "metadata": {},
   "source": [
    "Now, I will create a feature for my own use that will not be used as a predictor. This will be a string representation of the exploitation types indicated in that row. I will also use it to count the combinations of exploitation types seen to gain an understanding of distributions. \n",
    "\n",
    "\n",
    "example: isForcedLabor=1, isSexualExploit=1, isOtherExploit=0 -> Labor + Sexual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 2)\n",
      "┌─────────────────────────┬───────┐\n",
      "│ exploitation_types      ┆ count │\n",
      "│ ---                     ┆ ---   │\n",
      "│ str                     ┆ u32   │\n",
      "╞═════════════════════════╪═══════╡\n",
      "│ Other Only              ┆ 65    │\n",
      "│ Labour + Other          ┆ 4     │\n",
      "│ Labour Only             ┆ 0     │\n",
      "│ Sexual Only             ┆ 0     │\n",
      "│ Labour + Sexual         ┆ 0     │\n",
      "│ Sexual + Other          ┆ 0     │\n",
      "│ Labour + Sexual + Other ┆ 0     │\n",
      "│ None                    ┆ 0     │\n",
      "└─────────────────────────┴───────┘\n"
     ]
    },
    {
     "ename": "ColumnNotFoundError",
     "evalue": "\"combo_code\" not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mColumnNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[171]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(combo_counts)\n\u001b[32m     53\u001b[39m     df = df.drop(\u001b[33m'\u001b[39m\u001b[33mcombo_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33misOtherExploit\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43midentify_exploit_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[171]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36midentify_exploit_combinations\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     44\u001b[39m combo_counts = (\n\u001b[32m     45\u001b[39m     pl.DataFrame({\u001b[33m'\u001b[39m\u001b[33mexploitation_types\u001b[39m\u001b[33m'\u001b[39m: all_labels})\n\u001b[32m     46\u001b[39m     .join(combo_counts, on=\u001b[33m'\u001b[39m\u001b[33mexploitation_types\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     .sort(\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m, descending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     51\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(combo_counts)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcombo_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43misOtherExploit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stats/lib/python3.12/site-packages/polars/dataframe/frame.py:8690\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, strict, *columns)\u001b[39m\n\u001b[32m   8607\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   8608\u001b[39m \u001b[33;03mRemove columns from the dataframe.\u001b[39;00m\n\u001b[32m   8609\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   8683\u001b[39m \u001b[33;03m└─────┘\u001b[39;00m\n\u001b[32m   8684\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   8685\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazyframe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopt_flags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueryOptFlags\n\u001b[32m   8687\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   8688\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8689\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m8690\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQueryOptFlags\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8691\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stats/lib/python3.12/site-packages/polars/_utils/deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stats/lib/python3.12/site-packages/polars/lazyframe/opt_flags.py:328\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    327\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stats/lib/python3.12/site-packages/polars/lazyframe/frame.py:2422\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2420\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2421\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mColumnNotFoundError\u001b[39m: \"combo_code\" not found"
     ]
    }
   ],
   "source": [
    "def identify_exploit_combinations(df):\n",
    "    # build a 3-character code like \"110\" from the three binary flags,\n",
    "    # treating any nulls as 0 so that missing values are counted as \"no\"\n",
    "    df = df.with_columns([\n",
    "        (\n",
    "            pl.col('isForcedLabour').fill_null(0).cast(pl.Int8).cast(pl.String)\n",
    "            + pl.col('isSexualExploit').fill_null(0).cast(pl.Int8).cast(pl.String)\n",
    "            + pl.col('isOtherExploit').fill_null(0).cast(pl.Int8).cast(pl.String)\n",
    "        ).alias('combo_code')\n",
    "    ])\n",
    "\n",
    "    code_to_label = {\n",
    "        '100': 'Labour Only',\n",
    "        '010': 'Sexual Only',\n",
    "        '001': 'Other Only',\n",
    "        '000': 'None',\n",
    "        '110': 'Labour + Sexual',\n",
    "        '101': 'Labour + Other',\n",
    "        '011': 'Sexual + Other',\n",
    "        '111': 'Labour + Sexual + Other',\n",
    "    }\n",
    "\n",
    "    # add readable labels to original rows\n",
    "    df = df.with_columns(\n",
    "        pl.col('combo_code').replace(code_to_label).alias('exploitation_types')\n",
    "    )\n",
    "\n",
    "    # counts for categories that actually occur\n",
    "    combo_counts = (\n",
    "        df\n",
    "        .group_by('exploitation_types')\n",
    "        .len()\n",
    "        .rename({'len': 'count'})\n",
    "    )\n",
    "\n",
    "    # full set of labels (ensures missing combinations still appear with 0 count)\n",
    "    all_labels = [\n",
    "        'Labour Only',\n",
    "        'Sexual Only',\n",
    "        'Other Only',\n",
    "        'Labour + Sexual',\n",
    "        'Labour + Other',\n",
    "        'Sexual + Other',\n",
    "        'Labour + Sexual + Other',\n",
    "        'None'\n",
    "    ]\n",
    "\n",
    "    combo_counts = (\n",
    "        pl.DataFrame({'exploitation_types': all_labels})\n",
    "        .join(combo_counts, on='exploitation_types', how='left')\n",
    "        .with_columns(\n",
    "            pl.col('count').fill_null(0).cast(pl.UInt32)\n",
    "        )\n",
    "        .sort('count', descending=True)\n",
    "    )\n",
    "\n",
    "    print(combo_counts)\n",
    "    df = df.drop('combo_code', 'isOtherExploit')\n",
    "    return df\n",
    "\n",
    "# update df in-place with the new exploitation_types column and dropped isOtherExploit\n",
    "df = identify_exploit_combinations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9742cf",
   "metadata": {},
   "source": [
    "Above, we see that there are no instances of \"None\", and a small number of instances after combinations of labor + sexual exploitation. For this reason, I will not consider \"Other\" as its own category of exploitation. Not due to a lack of value, but due to the nature of the dataset at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef20192",
   "metadata": {},
   "source": [
    "Now, I will rename the columns for stylistic reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "541c4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .rename({\n",
    "        \"ageBroad\": \"Age Band\",\n",
    "        \"traffickMonths\": \"Trafficking Duration\",\n",
    "        \"meansDebtBondageEarnings\": \"Means Debt Bondage Earnings\",\n",
    "        \"meansThreats\": \"Means Threats\",\n",
    "        \"meansAbusePsyPhySex\": \"Means Abuse\",\n",
    "        \"meansFalsePromises\": \"Means False Promises\",\n",
    "        \"meansDrugsAlcohol\": \"Means Drugs Alcohol\",\n",
    "        \"meansDenyBasicNeeds\": \"Means Deny Basic Needs\",\n",
    "        \"meansExcessiveWorkHours\": \"Means Excessive Work Hours\",\n",
    "        \"meansWithholdDocs\": \"Means Withhold Docs\",\n",
    "        \"recruiterRelationIntimatePartner\": \"Recruiter Relation Intimate Partner\",\n",
    "        \"recruiterRelationFriend\": \"Recruiter Relation Friend\",\n",
    "        \"recruiterRelationFamily\": \"Recruiter Relation Family\",\n",
    "        \"recruiterRelationOther\": \"Recruiter Relation Other\",\n",
    "        \"gender_Trans/Transgender/NonConforming\": \"Gender:Transgender/NonConforming\",\n",
    "        \"gender_Woman\": \"Gender:Woman\",\n",
    "        \"isCitizenOfCountry\": \"Is Citizen of Country\"\n",
    "        })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b4d25724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 21)\n",
      "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ statistic ┆ Age Band ┆ Trafficki ┆ Means     ┆ … ┆ Gender:Tr ┆ Gender:Wo ┆ Is        ┆ exploitat │\n",
      "│ ---       ┆ ---      ┆ ng        ┆ Debt      ┆   ┆ ansgender ┆ man       ┆ Citizen   ┆ ion_types │\n",
      "│ str       ┆ f64      ┆ Duration  ┆ Bondage   ┆   ┆ /NonConfo ┆ ---       ┆ of        ┆ ---       │\n",
      "│           ┆          ┆ ---       ┆ Earnings  ┆   ┆ rmi…      ┆ f64       ┆ Country   ┆ str       │\n",
      "│           ┆          ┆ f64       ┆ ---       ┆   ┆ ---       ┆           ┆ ---       ┆           │\n",
      "│           ┆          ┆           ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
      "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ count     ┆ 91043.0  ┆ 91043.0   ┆ 91043.0   ┆ … ┆ 91043.0   ┆ 91043.0   ┆ 91043.0   ┆ 69        │\n",
      "│ null_coun ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 90974     │\n",
      "│ t         ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "│ mean      ┆ 2.007238 ┆ 0.00078   ┆ 0.159485  ┆ … ┆ 0.002977  ┆ 0.773843  ┆ 0.113177  ┆ null      │\n",
      "│ std       ┆ 2.643895 ┆ 0.034274  ┆ 0.36613   ┆ … ┆ 0.054477  ┆ 0.418344  ┆ 0.316811  ┆ null      │\n",
      "│ min       ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ Labour +  │\n",
      "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆ Other     │\n",
      "│ 25%       ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 1.0       ┆ 0.0       ┆ null      │\n",
      "│ 50%       ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 1.0       ┆ 0.0       ┆ null      │\n",
      "│ 75%       ┆ 3.0      ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 1.0       ┆ 0.0       ┆ null      │\n",
      "│ max       ┆ 9.0      ┆ 3.0       ┆ 1.0       ┆ … ┆ 1.0       ┆ 1.0       ┆ 1.0       ┆ Other     │\n",
      "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆ Only      │\n",
      "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c2045",
   "metadata": {},
   "source": [
    "We see 0 in the \"null_count\" column for all features, so we are good to go. I will save the final dataset and begin analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0e74bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write_csv('data/final_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
